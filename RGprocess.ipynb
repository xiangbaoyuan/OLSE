{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f78477",
   "metadata": {},
   "source": [
    "# 线性统计模型-数据分析报告处理过程代码MarkDown文档\n",
    "### 一、数据介绍\n",
    "\n",
    "#### 1.1 数据来源\n",
    "\n",
    "数据来自阿里云天池大赛练习赛题，赛题以二手车市场为背景，要求选手预测二手汽车的交易价格，这是一个典型的回归问题，刚好可以用于本次线性统计模型的课程报告。\n",
    "\n",
    "#### 1.2 数据字段介绍\n",
    "|     **Field**     |                       **Description**                        |\n",
    "| :---------------: | :----------------------------------------------------------: |\n",
    "|      SaleID       |                       交易ID，唯一编码                       |\n",
    "|       name        |                     汽车交易名称，已脱敏                     |\n",
    "|      regDate      |          汽车注册日期，例如20160101，2016年01月01日          |\n",
    "|       model       |                       车型编码，已脱敏                       |\n",
    "|       brand       |                       汽车品牌，已脱敏                       |\n",
    "|     bodyType      | 车身类型：豪华轿车：0，微型车：1，厢型车：2，大巴车：3，敞篷车：4，双门汽车：5，商务车：6，搅拌车：7 |\n",
    "|     fuelType      | 燃油类型：汽油：0，柴油：1，液化石油气：2，天然气：3，混合动力：4，其他：5，电动：6 |\n",
    "|      gearbox      |                   变速箱：手动：0，自动：1                   |\n",
    "|       power       |                 发动机功率：范围 [ 0, 600 ]                  |\n",
    "|     kilometer     |                   汽车已行驶公里，单位万km                   |\n",
    "| notRepairedDamage |              汽车有尚未修复的损坏：是：0，否：1              |\n",
    "|    regionCode     |                       地区编码，已脱敏                       |\n",
    "|      seller       |                  销售方：个体：0，非个体：1                  |\n",
    "|     offerType     |                  报价类型：提供：0，请求：1                  |\n",
    "|     creatDate     |                 汽车上线时间，即开始售卖时间                 |\n",
    "|       price       |                  二手车交易价格（预测目标）                  |\n",
    "|     v系列特征     |             匿名特征，包含v0-14在内15个匿名特征              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197573f6",
   "metadata": {},
   "source": [
    "### 二、特征工程\n",
    "\n",
    "#### 2.1 读取并观察各数据情况\n",
    "\n",
    "##### 2.1.1 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f51110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#导入warnings包，利用过滤器来实现忽略警告语句。\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb57cf",
   "metadata": {},
   "source": [
    "##### 2.1.2 读取数据文件\n",
    "\n",
    "该数据文件被分为训练集与数据集需要分别读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96bb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/car/'\n",
    "Train_data = pd.read_csv(path+'used_car_train_20200313.csv', sep=' ')\n",
    "Test_data = pd.read_csv(path+'used_car_testB_20200421.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc57d3",
   "metadata": {},
   "source": [
    "##### 2.1.3 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bf011b",
   "metadata": {},
   "source": [
    "可以发现：\n",
    "\n",
    "- 此训练集数据共有15万各样本，存在30个变量，虽然变量类型仅notRepairedDamage不是数值型，但里面存在用数字表示的类别变量值得注意\n",
    "- 其中bodyType等四个字段存在缺失值，等待后续处理\n",
    "- v_0-v_14数据字段采用了脱敏处理，删除了数据具体含义\n",
    "- price将是我们要预测的因变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea232ae6",
   "metadata": {},
   "source": [
    "因为仅notRepairedDamage为object数据，故我们需要详细看一下其数据值的具体内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data['notRepairedDamage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae745d8f",
   "metadata": {},
   "source": [
    "通过上面结果可以发现该数据里面存在“-”符号表示的数据，这也是原始数据中常用来表示缺失值的符号，因为后续模型不一定会用上，故在此先不做处理，而是将其替换为nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51cf2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data['notRepairedDamage'].replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c40af7d",
   "metadata": {},
   "source": [
    "查看训练集的缺失情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99143264",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = Train_data.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()\n",
    "# 将缺失数量显示在条形图上方\n",
    "x = range(0, len(missing))\n",
    "for a, b in zip(x, missing):\n",
    "    plt.text(a, b + 2, b, ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9eb74",
   "metadata": {},
   "source": [
    "通过上图可以直观的发现哪些数据存在缺失，由于暂不确定是否会采用这些变量用于建模，故先不对其进行处理，以免造成信息缺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a06c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 9) #设置最大列数\n",
    "Train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2734eeb",
   "metadata": {},
   "source": [
    "上面结果显示了数据的统计信息，包括样本数、样本均值等，能对数据的一些情况有大概了解。\n",
    "\n",
    "查看部分数据字段信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d248e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c092ca",
   "metadata": {},
   "source": [
    "上面显示了数据集的前五条数据，可以发现存在日期变量，用1，2，3等数字表示的类别变量以及大多数浮点数表示的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e8d6c",
   "metadata": {},
   "source": [
    "##### 2.1.4 数据分离\n",
    "\n",
    "特征分为类别特征和数值型特征，我们需要分别处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04430465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离label即预测值\n",
    "Y_train = Train_data['price']\n",
    "\n",
    "\n",
    "sns.boxplot(np.log(Y_train+1),orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50573cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里需要人为根据实际含义来区分数据类型\n",
    "# 数字特征\n",
    "numeric_features = ['power', 'kilometer', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', \n",
    "                    'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13','v_14' ]\n",
    "# 类型特征\n",
    "categorical_features = ['name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox', 'notRepairedDamage', 'regionCode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c4655",
   "metadata": {},
   "source": [
    "##### 2.1.5数字特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将因变量加入一起分析\n",
    "numeric_features.append('price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcae593",
   "metadata": {},
   "source": [
    "1）相关性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d492782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看各数字特征与因变量之间的相关系数\n",
    "price_numeric = Train_data[numeric_features]\n",
    "correlation = price_numeric.corr()\n",
    "print(correlation['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94f05f",
   "metadata": {},
   "source": [
    "通过上面结果可以大致观察出因变量与特征之间的关系强弱，在后续可以考虑设置相应的相关系数阈值来进行变量选取，例如选取相关系数在0.5以上的特征用于回归分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ee199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制相关系数矩阵热力图\n",
    "f , ax = plt.subplots(figsize = (7, 7))\n",
    "\n",
    "from pylab import mpl\n",
    "mpl.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体\n",
    "mpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "plt.title('相关系数矩阵热力图',y=1,size=16)\n",
    "\n",
    "sns.heatmap(correlation,square = True,  vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb38eeb7",
   "metadata": {},
   "source": [
    "通过上图可以直观的观察各变量之间的相关性强弱，可以大致看出哪些变量间存在多重共线性，例如v_0和v_3可能存在较强的相关性，可以为后续变量选择或是特征降维工作提供一定的选择基础\n",
    "\n",
    "2）单变量回归与密度图展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb066cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 线性回归关系图\n",
    "# #numeric_features.remove('price')\n",
    "# fcols = 6\n",
    "# frows = len(numeric_features)\n",
    "# plt.figure(figsize=(5*fcols,4*frows))\n",
    "\n",
    "# i = 0\n",
    "# for col in numeric_features:\n",
    "#     # 绘制回归图\n",
    "#     i = i+1\n",
    "#     ax = plt.subplot(frows,fcols,i)\n",
    "#     sns.regplot(x=col, y='price', data=price_numeric, ax=ax,\n",
    "#                scatter_kws = {'marker':'.', 's':3, 'alpha':0.3},\n",
    "#                line_kws = {'color':'k'})\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel('price')\n",
    "    \n",
    "#     # 绘制分布图\n",
    "#     i = i+1\n",
    "#     ax = plt.subplot(frows,fcols,i)\n",
    "#     sns.distplot(price_numeric[col].dropna())\n",
    "#     plt.xlabel(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3db2b4",
   "metadata": {},
   "source": [
    "##### 2.1.6类别特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fea in categorical_features:\n",
    "    print(fea,end='\\t')\n",
    "    print(Train_data[fea].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8148b8",
   "metadata": {},
   "source": [
    "可以发现：name和regionCode的类别过于稀疏，不适宜用于类别特征分析，先将其剔除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb5e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features.remove('name')\n",
    "categorical_features.remove('regionCode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c19a56d",
   "metadata": {},
   "source": [
    "绘制箱线图观察各类别变量分布情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9adc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18, 10))\n",
    "# plt.boxplot(x=Train_data[categorical_features].values,labels=categorical_features)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Train_data[categorical_features].values\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef90eb",
   "metadata": {},
   "source": [
    "### 三、模型拟合\n",
    "\n",
    "本部分先仅对数值型特征进行拟合分析，观察拟合效果后视情况讨论类别特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25c8cd",
   "metadata": {},
   "source": [
    "#### 3.1 代码准备\n",
    "\n",
    "对于该数据的回归模型拟合采用普通最小二乘方法实现，其中包括最小二乘参数估计、拟合优度计算、单参数检验、F检验、回归诊断、结果输出几个部分，各部分代码通过函数封装，代码展示如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def LeastSquareMethod(X, y):\n",
    "    '''\n",
    "        最小二乘法实现\n",
    "        参数：\n",
    "        X    自变量矩阵\n",
    "        y    因变量\n",
    "        返回值：\n",
    "        Beta_hat     系数估计值\n",
    "        y_hat        y估计值\n",
    "        error_hat    残差\n",
    "    '''\n",
    "\n",
    "    mat_temp = X.T * X  # .T表示转置\n",
    "    Beta_hat = mat_temp.I * X.T * y  # .I表示矩阵求逆\n",
    "\n",
    "    y_hat = X * Beta_hat\n",
    "    error_hat = y - y_hat\n",
    "\n",
    "    return Beta_hat, y_hat, error_hat\n",
    "\n",
    "\n",
    "def GoodnessOfFit(y, error_hat, N, K):\n",
    "    '''\n",
    "        拟合优度计算\n",
    "        参数：\n",
    "        y          真实的y\n",
    "        error_hat  残差\n",
    "        N          样本量\n",
    "        K          参数个数\n",
    "        返回值：\n",
    "        R_square            拟合优度\n",
    "        Adjusted_R_square   叫做后的拟合优度\n",
    "    '''\n",
    "\n",
    "    SSE = sum(np.multiply(error_hat, error_hat))\n",
    "    SST = sum(np.multiply(y - y.mean(), y - y.mean()))\n",
    "\n",
    "    R_square = 1 - SSE / SST\n",
    "    Adjusted_R_square = 1 - (SSE / (N - K)) / (SST / (N - 1))\n",
    "\n",
    "    return R_square, Adjusted_R_square\n",
    "\n",
    "\n",
    "def TTest(X, Beta_hat, error_hat, Beta_test):\n",
    "    '''\n",
    "        单个参数检验\n",
    "        参数：\n",
    "        X           自变量矩阵\n",
    "        Beta_hat    系数估计值\n",
    "        error_hat   残差\n",
    "        Beta_test   用于原假设的Beta值，一般为0向量\n",
    "        返回值：\n",
    "        P           各参数检验的P值\n",
    "    '''\n",
    "\n",
    "    # 计算Beat_hat的方差\n",
    "    mat_temp = np.diagonal((X.T * X).I)\n",
    "    freedom = X.shape[0] - X.shape[1]\n",
    "    Beta_var_hat = ((error_hat.T * error_hat / freedom) * mat_temp).T\n",
    "\n",
    "    # 通过t值计算检验的P值\n",
    "    t = (Beta_hat - Beta_test) / np.sqrt(Beta_var_hat)\n",
    "    P = 2 * sta.t.sf(t, freedom)\n",
    "\n",
    "    return Beta_var_hat, P\n",
    "\n",
    "\n",
    "def FTest(y, error_hat, N, K):\n",
    "    '''\n",
    "        F检验\n",
    "        参数：\n",
    "        y          真实的y\n",
    "        error_hat  残差\n",
    "        N          样本量\n",
    "        K          参数个数\n",
    "        返回值：\n",
    "        P           各参数检验的P值\n",
    "    '''\n",
    "\n",
    "    SSE = sum(np.multiply(error_hat, error_hat))\n",
    "    SST = sum(np.multiply(y - y.mean(), y - y.mean()))\n",
    "    SSR = SST - SSE\n",
    "\n",
    "    # 计算自由度\n",
    "    freedom_SSR = K - 1\n",
    "    freedom_SSE = N - K\n",
    "\n",
    "    # 通过F值计算检验的P值\n",
    "    F = (SSR / freedom_SSR) / (SSE / freedom_SSE)\n",
    "    P = sta.f.sf(F, freedom_SSR, freedom_SSE)\n",
    "\n",
    "    return P\n",
    "\n",
    "\n",
    "def ErrorRatio(y, y_hat):\n",
    "    '''\n",
    "        输入：\n",
    "        y     真实值\n",
    "        y_hat 估计值\n",
    "        输出：\n",
    "        ErrorRatio 误差百分比\n",
    "    '''\n",
    "    temp = abs(y - y_hat) / y * 100\n",
    "\n",
    "    return temp.sum() / len(y)\n",
    "\n",
    "\n",
    "def RegressionDiagnosis(X, y_hat, error_hat):\n",
    "    '''\n",
    "        回归诊断\n",
    "        参数：\n",
    "        X           自变量矩阵\n",
    "        error_hat   残差\n",
    "        返回值：\n",
    "    '''\n",
    "    \n",
    "    mu = error_hat.mean()\n",
    "    sigma = error_hat.std()\n",
    "    # 绘制残差直方图观察残差是否服从正态分布\n",
    "    if len(error_hat) > 100:\n",
    "        num_bins = 30  # 直方图柱子的数量\n",
    "    else:\n",
    "        num_bins = 10\n",
    "    n, bins, patches = plt.hist(error_hat, num_bins, density=1, facecolor='blue', alpha=0.5)\n",
    "    # n, bins, patches = plt.hist(error_hat, density=1)\n",
    "    y = sta.norm.pdf(bins, mu, sigma)  # 拟合一条最佳正态分布曲线y\n",
    "    plt.plot(bins, y, 'r--')  # 绘制y的曲线\n",
    "    plt.xlabel('sepal-length')  # 绘制x轴\n",
    "    plt.ylabel('Probability')  # 绘制y轴\n",
    "    plt.title(r'Histogram : $\\mu=%.3f$,$\\sigma=%.3f$' % (mu, sigma))  # 中文标题 u'xxx'\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    # 绘制qq图\n",
    "    sta.probplot(np.array(error_hat).reshape(1,len(error_hat))[0], dist=\"norm\", plot=plt)\n",
    "    plt.title('(a)')\n",
    "    # 绘制残差与y_hat的散点图\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(np.array(y_hat), np.array(error_hat))\n",
    "    plt.axhline(0, c=\"red\")\n",
    "    plt.title('(b)')\n",
    "\n",
    "    return\n",
    "\n",
    "def TheResultsShow(X, y):\n",
    "    N = X.shape[0]\n",
    "    K = X.shape[1]\n",
    "    freedom = N - K\n",
    "    Beta_test = np.mat(np.zeros(K)).T\n",
    "\n",
    "    Beta_hat, y_hat, error_hat = LeastSquareMethod(X, y)\n",
    "    R_square, Adjusted_R_square = GoodnessOfFit(y, error_hat, N, K)\n",
    "    Beta_var_hat, Pt = TTest(X, Beta_hat, error_hat, Beta_test)\n",
    "    Pf = FTest(y, error_hat, N, K)\n",
    "    MSE = error_hat.T * error_hat / freedom\n",
    "    error_ratio = ErrorRatio(y, y_hat)\n",
    "\n",
    "    # 打印\n",
    "    print('+{x:-^{y}}+'.format(x='', y=6 + len('Number of obs')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Prob > F')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('R-squared')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Adj R-squared')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=8 + len('MSE')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('ErrorRatio')))\n",
    "    print('|{x:^{y}}|'.format(x='Number of obs', y=6 + len('Number of obs')) +\n",
    "          '{x:^{y}}|'.format(x='Prob > F', y=6 + len('Prob > F')) +\n",
    "          '{x:^{y}}|'.format(x='R-squared', y=6 + len('R-squared')) +\n",
    "          '{x:^{y}}|'.format(x='Adj R-squared', y=6 + len('Adj R-squared')) +\n",
    "          '{x:^{y}}|'.format(x='MSE', y=8 + len('MSE')) +\n",
    "          '{x:^{y}}|'.format(x='ErrorRatio', y=6 + len('ErrorRatio')))\n",
    "    print('+{x:-^{y}}+'.format(x='', y=6 + len('Number of obs')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Prob > F')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('R-squared')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Adj R-squared')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=8 + len('MSE')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('ErrorRatio')))\n",
    "    print('|{x:^{y}}|'.format(x='%d' % N, y=6 + len('Number of obs')) +\n",
    "          '{x:^{y}}|'.format(x='%.3f' % Pf, y=6 + len('Prob > F')) +\n",
    "          '{x:^{y}}|'.format(x='%.3f' % R_square, y=6 + len('R-squared')) +\n",
    "          '{x:^{y}}|'.format(x='%.3f' % Adjusted_R_square, y=6 + len('Adj R-squared')) +\n",
    "          '{x:^{y}}|'.format(x='%.3f' % MSE, y=8 + len('MSE')) +\n",
    "          '{x:^{y}}|'.format(x='%.3f' % error_ratio, y=6 + len('ErrorRatio')))\n",
    "    print('+{x:-^{y}}+'.format(x='', y=6 + len('Number of obs')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Prob > F')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('R-squared')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Adj R-squared')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=8 + len('MSE')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('ErrorRatio')))\n",
    "\n",
    "    print('+{x:-^{y}}+'.format(x='', y=6 + len('Beta_hat')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Beta_hat')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Std. err.')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('P>|t|')))\n",
    "    print('|{x:^{y}}|'.format(x='', y=6 + len('Beta_hat')) +\n",
    "          '{x:^{y}}|'.format(x='Beta_hat', y=6 + len('Beta_hat')) +\n",
    "          '{x:^{y}}|'.format(x='Std. err.', y=6 + len('Std. err.')) +\n",
    "          '{x:^{y}}|'.format(x='P>|t|', y=6 + len('P>|t|')))\n",
    "    print('+{x:-^{y}}+'.format(x='', y=6 + len('Beta_hat')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Beta_hat')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('Std. err.')) +\n",
    "          '{x:-^{y}}+'.format(x='', y=6 + len('P>|t|')))\n",
    "    for i in range(len(Beta_hat)):\n",
    "        print('|{x:^{y}}|'.format(x='Beta_%d' % i, y=6 + len('Beta_hat')) +\n",
    "              '{x:^{y}}|'.format(x='%.3f' % Beta_hat[i], y=6 + len('Beta_hat')) +\n",
    "              '{x:^{y}}|'.format(x='%.3f' % Beta_var_hat[i], y=6 + len('Std. err.')) +\n",
    "              '{x:^{y}}|'.format(x='%.3f' % Pt[i], y=6 + len('P>|t|')))\n",
    "        # %(i+1, Beta_hat1[i], Beta_hat2[i], Beta_hat3[i]))\n",
    "        print('+{x:-^{y}}+'.format(x='', y=6 + len('Beta_hat')) +\n",
    "              '{x:-^{y}}+'.format(x='', y=6 + len('Beta_hat')) +\n",
    "              '{x:-^{y}}+'.format(x='', y=6 + len('Std. err.')) +\n",
    "              '{x:-^{y}}+'.format(x='', y=6 + len('P>|t|')))\n",
    "\n",
    "    # 如果数据为2维或3维则绘图展示\n",
    "    if K == 2:\n",
    "        plt.scatter(np.array(X[:,1]), np.array(y))\n",
    "        plt.plot(np.array(X[:,1]), np.array(y_hat), c='red')\n",
    "        plt.show()\n",
    "    elif K == 3:\n",
    "        ax = plt.axes(projection='3d')  # 绘制3d图形\n",
    "        ax.scatter(np.array(X[:, 1]), np.array(X[:, 2]), np.array(y), c='r')\n",
    "        arr_X, arr_Y = np.meshgrid(np.array(X[:,1]), np.array(X[:,2]))\n",
    "        Z = float(Beta_hat[0]) + float(Beta_hat[1])*arr_X + float(Beta_hat[2])*arr_Y\n",
    "        ax.plot_surface(arr_X, arr_Y, Z, alpha=0.5, color = \"g\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('维数太高无法绘图展示')\n",
    "\n",
    "    RegressionDiagnosis(X, y_hat, error_hat)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4bf9df",
   "metadata": {},
   "source": [
    "#### 3.2 模型拟合兼特征选取\n",
    "\n",
    "为避免过拟合，本部分先将把数据集分为两部分，一部分用于训练，一部分用于检验拟合效果，确定最终变量选取后再将对应的所有数据用于模型求解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932e8d3",
   "metadata": {},
   "source": [
    "##### 3.2.1 数据分割与转换\n",
    "\n",
    "因为所写的参数估计部分代码采用的是矩阵计算，故需要将数据转换为矩阵形式\n",
    "\n",
    "power变量极端情况严重，选择删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832829fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过sklearn的函数进行数据分割，将百分之十的数据用于验证\n",
    "from sklearn.model_selection import train_test_split\n",
    "price_numeric = price_numeric.drop(['price','power'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(price_numeric, Y_train, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过2.1.5的相关系数分析结果我们先将相关系数大于0.5的变量选出用于分析\n",
    "cor = correlation['price']\n",
    "cor = cor.drop('price')\n",
    "cor = cor.drop('power')\n",
    "\n",
    "X_train1 = X_train[cor.index[abs(cor.values)>0.5]]\n",
    "X_test1 = X_test[cor.index[abs(cor.values)>0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换成矩阵形式，并生成增广矩阵\n",
    "X_test1_mat = np.mat(X_test1)\n",
    "X_ones = np.mat(np.ones(X_test1_mat.shape[0])).T\n",
    "X_test1_mat = np.append(X_ones, X_test1_mat, axis=1)\n",
    "\n",
    "X_train1_mat = np.mat(X_train1)\n",
    "X_ones = np.mat(np.ones(X_train1_mat.shape[0])).T\n",
    "X_train1_mat = np.append(X_ones, X_train1_mat, axis=1)\n",
    "\n",
    "# 转换y\n",
    "y_train_mat = np.mat(y_train).T\n",
    "y_test_mat = np.mat(y_test).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eef2c2",
   "metadata": {},
   "source": [
    "##### 3.2.2 模型拟合\n",
    "\n",
    "采用自己编写普通最小二乘代码进行模型拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02133d7",
   "metadata": {},
   "source": [
    "由于变量尺度的问题，通过简单的MSE进行误差评估显然已经无法满足要求，下面我们采用误差占比的方式进行误差评估\n",
    "$$\n",
    "ErrorRatio = \\frac{\\sum{\\frac{|y-\\hat{y}|}{y}\\times 100}}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67125a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑暴力添加，直接将所有不含nan的数值型变量加入该模型进行分析\n",
    "X_train3_mat = np.mat(X_train.dropna(axis=1))\n",
    "X_ones = np.mat(np.ones(X_train3_mat.shape[0])).T\n",
    "X_train3_mat = np.append(X_ones, X_train3_mat, axis=1)\n",
    "\n",
    "TheResultsShow(X_train3_mat, y_train_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38c6d9",
   "metadata": {},
   "source": [
    "通过作图我们发现数据的标签（price）呈现长尾分布，不利于我们的建模预测。原因是很多模型都假设数据误差项符合正态分布，而长尾分布的数据违背了这一假设。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bfd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(y_train)\n",
    "plt.title('(a)')\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(y_train[y_train < np.quantile(y_train, 0.9)])\n",
    "plt.title('(b)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_ln = np.log(y_train + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(train_y_ln)\n",
    "plt.title('(a)')\n",
    "plt.subplot(1,2,2)\n",
    "sta.probplot(np.array(train_y_ln).reshape(1,len(train_y_ln))[0], dist=\"norm\", plot=plt)\n",
    "plt.title('(b)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_ln = np.mat(train_y_ln).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a428473",
   "metadata": {},
   "outputs": [],
   "source": [
    "TheResultsShow(X_train3_mat, train_y_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1edcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_y_ln,orient=\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271530f3",
   "metadata": {},
   "source": [
    "通过上面的结果可以发现模型在第三个变量的P值很大，在这里考虑将其删除再拟合一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加相关系数大于0.1的变量\n",
    "X_train4 = X_train[cor.index[abs(cor.values)>0.1]]\n",
    "\n",
    "X_train4_mat = np.mat(X_train4)\n",
    "X_ones = np.mat(np.ones(X_train4_mat.shape[0])).T\n",
    "X_train4_mat = np.append(X_ones, X_train4_mat, axis=1)\n",
    "\n",
    "TheResultsShow(X_train4_mat, train_y_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c431fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TheResultsShow(X_train1_mat, train_y_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e89b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_mat = np.delete(X_train1_mat, 2, axis=1)\n",
    "TheResultsShow(X_train2_mat, train_y_ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519db1c",
   "metadata": {},
   "source": [
    "可以发现删除第二个变量后该模型的其他特征全部通过了检验，但该模型的拟合优度为0.621，相对来说较低，而且我们还有许多变量还未用上，故下面考虑增加变量来进行模型拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419853e7",
   "metadata": {},
   "source": [
    "####  统计预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d634359",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aaf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta_hat, y_hat, error_hat = LeastSquareMethod(X_train2_mat, train_y_ln)\n",
    "\n",
    "X_test_mat = X_test[['v_0', 'v_8', 'v_12']]\n",
    "X_test_mat = np.mat(X_test_mat)\n",
    "X_ones = np.mat(np.ones(X_test_mat.shape[0])).T\n",
    "X_test_mat = np.append(X_ones, X_test_mat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_ln = X_test_mat * Beta_hat\n",
    "y_pre_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e642e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = np.exp(y_pre_ln)-1\n",
    "error_hat = y_test_mat - y_pre\n",
    "\n",
    "RegressionDiagnosis(X_test_mat, y_pre, error_hat)\n",
    "\n",
    "er = ErrorRatio(y_test_mat, y_pre)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看训练集与测试集的数据分布是否一致\n",
    "dist_cols = 3\n",
    "dist_rows = 1\n",
    "plt.figure(figsize=(4*dist_cols,4*dist_rows))\n",
    "i = 1\n",
    "for col in ['v_0', 'v_8', 'v_12']:\n",
    "    ax = plt.subplot(dist_rows, dist_cols, i)\n",
    "    ax = sns.kdeplot(X_train[col],color='red',shade=True)\n",
    "    ax = sns.kdeplot(X_test[col],color='blue',shade=True)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax = ax.legend(['train', 'test'])\n",
    "    i = i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_y_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08047f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.boxplot(np.log(y_test+1),orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89126ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(np.log(y_test+1))\n",
    "plt.title('(a)')\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(np.log(y_test+1)[np.log(y_test+1) < np.quantile(np.log(y_test+1), 0.9)])\n",
    "plt.title('(b)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f861039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xxx(X, error_hat):\n",
    "    # 计算标准化残差\n",
    "    freedom = X.shape[0] - X.shape[1]\n",
    "    theta = np.sqrt(error_hat.T * error_hat / freedom)\n",
    "    Std_error = error_hat / theta\n",
    "\n",
    "    # 计算学生化残差\n",
    "    mat_temp = X.T * X\n",
    "    Hii = np.diagonal(X * mat_temp.I * X.T)\n",
    "    Stu_error = error_hat / (theta * np.sqrt(1-Hii)).T\n",
    "\n",
    "    # 计算DFFITS\n",
    "    MSE = error_hat.T * error_hat / freedom\n",
    "    DFFITSi = error_hat / np.sqrt(MSE * Hii).T\n",
    "\n",
    "    # 计算Cook distances\n",
    "    k = X.shape[1]\n",
    "    temp1 = np.multiply(error_hat, error_hat) / (k*MSE)\n",
    "    temp2 = np.mat(Hii / np.multiply(1-Hii, 1-Hii))\n",
    "    Di = np.multiply(temp1, temp2.T)\n",
    "    \n",
    "    return Di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑3sigma原则删除异常数据\n",
    "#设定法则的左右边界\n",
    "left=y_train.mean()-3*y_train.std()\n",
    "right=y_train.mean()+3*y_train.std()\n",
    "\n",
    "#获取在范围内的数据\n",
    "new_num_y=y_train[(left>y_train)|(y_train>right)]\n",
    "new_num_y\n",
    "\n",
    "y_new = y_train.drop(new_num_y.index[:])\n",
    "y_new = np.mat(y_new)\n",
    "y_new_ln = np.log(y_new+1).T\n",
    "y_new_ln\n",
    "\n",
    "sns.boxplot(y_new_ln,orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfebd835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 索引数据量太大无法直接截取，所以我们采取删除不满足条件的数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cc99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_new = X_train.drop(new_num_y.index[:])\n",
    "X_train_new = X_train_new[['v_0', 'v_8', 'v_12']]\n",
    "\n",
    "X_train_new = np.mat(X_train_new)\n",
    "X_ones = np.mat(np.ones(X_train_new.shape[0])).T\n",
    "X_train_new = np.append(X_ones, X_train_new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09827e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "TheResultsShow(X_train_new, y_new_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33610357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta_hat, y_hat, error_hat = LeastSquareMethod(X_train_new, y_new_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e65acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_ln = X_test_mat * Beta_hat\n",
    "y_pre_ln\n",
    "\n",
    "y_pre = np.exp(y_pre_ln)-1\n",
    "error_hat = y_test_mat - y_pre\n",
    "\n",
    "RegressionDiagnosis(X_test_mat, y_pre, error_hat)\n",
    "\n",
    "er = ErrorRatio(y_test_mat, y_pre)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取四分位数删除异常数据\n",
    "#设定法则的左右边界\n",
    "left=y_train.quantile(0.05)\n",
    "right=y_train.quantile(0.95)\n",
    "\n",
    "#获取在范围内的数据\n",
    "new_num_y=y_train[(left>y_train)|(y_train>right)]\n",
    "new_num_y\n",
    "\n",
    "y_new = y_train.drop(new_num_y.index[:])\n",
    "y_new = np.mat(y_new)\n",
    "y_new_ln = np.log(y_new+1).T\n",
    "y_new_ln\n",
    "\n",
    "sns.boxplot(y_new_ln,orient=\"v\")\n",
    "\n",
    "X_train_new = X_train.drop(new_num_y.index[:])\n",
    "X_train_new = X_train_new[['v_0', 'v_8', 'v_12']]\n",
    "\n",
    "X_train_new = np.mat(X_train_new)\n",
    "X_ones = np.mat(np.ones(X_train_new.shape[0])).T\n",
    "X_train_new = np.append(X_ones, X_train_new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b604f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TheResultsShow(X_train_new, y_new_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta_hat, y_hat, error_hat = LeastSquareMethod(X_train_new, y_new_ln)\n",
    "\n",
    "y_pre_ln = X_test_mat * Beta_hat\n",
    "y_pre_ln\n",
    "\n",
    "y_pre = np.exp(y_pre_ln)-1\n",
    "error_hat = y_test_mat - y_pre\n",
    "\n",
    "RegressionDiagnosis(X_test_mat, y_pre, error_hat)\n",
    "\n",
    "er = ErrorRatio(y_test_mat, y_pre)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑3sigma原则删除异常数据\n",
    "#设定法则的左右边界\n",
    "left=y_test.quantile(0.25)\n",
    "right=y_test.quantile(0.75)\n",
    "# left=y_test.mean()-3*y_test.std()\n",
    "# right=y_test.mean()+3*y_test.std()\n",
    "\n",
    "#获取在范围内的数据\n",
    "new_num_y_test=y_test[(left>y_test)|(y_test>right)]\n",
    "new_num_y_test\n",
    "\n",
    "\n",
    "y_new_test = y_test.drop(new_num_y_test.index[:])\n",
    "y_new_test = np.mat(y_new_test)\n",
    "y_new_test_ln = np.log(y_new_test+1).T\n",
    "y_new_test_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea27239",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = X_test.drop(new_num_y_test.index[:])\n",
    "X_test_new = X_test_new[['v_0', 'v_8', 'v_12']]\n",
    "\n",
    "X_test_new = np.mat(X_test_new)\n",
    "X_ones = np.mat(np.ones(X_test_new.shape[0])).T\n",
    "X_test_new = np.append(X_ones, X_test_new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff527b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_ln = X_test_new * Beta_hat\n",
    "y_pre_ln\n",
    "\n",
    "y_pre = np.exp(y_pre_ln)-1\n",
    "y_pre\n",
    "error_hat = y_new_test.T - y_pre\n",
    "\n",
    "RegressionDiagnosis(X_test_mat, y_pre, error_hat)\n",
    "\n",
    "er = ErrorRatio(y_new_test.T, y_pre)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c072b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y_new_test,orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取四分位数删除异常数据\n",
    "#设定法则的左右边界\n",
    "median=y_train.quantile(0.93)\n",
    "\n",
    "#获取在范围内的数据\n",
    "new_num_y=y_train[(median<y_train)]\n",
    "new_num_y\n",
    "\n",
    "y_new = y_train.drop(new_num_y.index[:])\n",
    "y_new = np.mat(y_new)\n",
    "y_new_ln = np.log(y_new+1).T\n",
    "y_new_ln\n",
    "\n",
    "sns.boxplot(y_new_ln,orient=\"v\")\n",
    "\n",
    "X_train_new = X_train.drop(new_num_y.index[:])\n",
    "X_train_new = X_train_new[['v_0', 'v_8', 'v_12']]\n",
    "\n",
    "X_train_new = np.mat(X_train_new)\n",
    "X_ones = np.mat(np.ones(X_train_new.shape[0])).T\n",
    "X_train_new = np.append(X_ones, X_train_new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TheResultsShow(X_train_new, y_new_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取在范围内的训练数据\n",
    "new_num_y_test=y_test[(median<y_test)]\n",
    "new_num_y_test\n",
    "\n",
    "y_new_test = y_test.drop(new_num_y_test.index[:])\n",
    "y_new_test = np.mat(y_new_test)\n",
    "\n",
    "\n",
    "X_test_new = X_test.drop(new_num_y_test.index[:])\n",
    "X_test_new = X_test_new[['v_0', 'v_8', 'v_12']]\n",
    "\n",
    "X_test_new = np.mat(X_test_new)\n",
    "X_ones = np.mat(np.ones(X_test_new.shape[0])).T\n",
    "X_test_new = np.append(X_ones, X_test_new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta_hat, y_hat, error_hat = LeastSquareMethod(X_train_new, y_new_ln)\n",
    "\n",
    "y_pre_ln = X_test_new * Beta_hat\n",
    "y_pre_ln\n",
    "\n",
    "y_pre = np.exp(y_pre_ln)-1\n",
    "y_pre\n",
    "\n",
    "y_test_mat = np.mat(y_test).T\n",
    "\n",
    "error_hat = y_new_test.T - y_pre\n",
    "\n",
    "RegressionDiagnosis(X_test_new, y_pre, error_hat)\n",
    "\n",
    "er = ErrorRatio(y_new_test.T, y_pre)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ed8c5",
   "metadata": {},
   "source": [
    "### 加入类别变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfdd468",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data1 = Train_data[['bodyType', 'fuelType', 'gearbox', 'v_0', 'v_8', 'v_12', 'price']]\n",
    "Train_data1 = Train_data1.dropna(axis=0, how='any', inplace=False)\n",
    "Y_train = Train_data1['price']\n",
    "X_train = Train_data1[['bodyType', 'fuelType', 'gearbox', 'v_0', 'v_8', 'v_12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_data1 = Train_data[['bodyType', 'fuelType', 'gearbox', 'v_0', 'v_8', 'v_12', 'price']]\n",
    "Train_data1 = Train_data.dropna(axis=0, how='any', inplace=False)\n",
    "Y_train = Train_data1['price']\n",
    "X_train = Train_data1[[ 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'bodyType', 'fuelType', 'gearbox',\n",
    "                       'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13','v_14']]\n",
    "# numeric_features = ['power', 'kilometer', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', \n",
    "#                     'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13','v_14' ]\n",
    "# # 类型特征\n",
    "# categorical_features = ['name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox', 'notRepairedDamage', 'regionCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = Train_data1.corr()\n",
    "print(correlation['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e258cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b4fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过sklearn的函数进行数据分割，将百分之十的数据用于验证\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f6edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑pca降维\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_09 = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c3213",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_09\n",
    "X_ones = np.mat(np.ones(X_train_09.shape[0])).T\n",
    "X_train_09 = np.append(X_ones, X_train_09, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94005ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_09 = pca.transform(X_test)\n",
    "X_ones = np.mat(np.ones(X_test_09.shape[0])).T\n",
    "X_test_09 = np.append(X_ones, X_test_09, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换y\n",
    "y_train_mat = np.mat(y_train).T\n",
    "y_test_mat = np.mat(y_test).T\n",
    "\n",
    "train_y_ln = np.log(y_train_mat + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta_hat, y_hat, error_hat = LeastSquareMethod(X_train_09, train_y_ln)\n",
    "\n",
    "y_pre_ln = X_test_09 * Beta_hat\n",
    "y_pre_ln\n",
    "\n",
    "y_pre = np.exp(y_pre_ln)-1\n",
    "y_pre\n",
    "\n",
    "y_test_mat = np.mat(y_test).T\n",
    "\n",
    "error_hat = y_test_mat - y_pre\n",
    "\n",
    "RegressionDiagnosis(X_test_09, y_pre, error_hat)\n",
    "\n",
    "er = ErrorRatio(y_test_mat, y_pre)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faaa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终采用PCA降维进行回归，导入所有训练数据\n",
    "Train_data1 = Train_data[['bodyType', 'fuelType', 'gearbox', 'v_0', 'v_8', 'v_12', 'price']]\n",
    "Train_data1 = Train_data1.dropna(axis=0, how='any', inplace=False)\n",
    "Y_train = Train_data1['price']\n",
    "X_train = Train_data1[['bodyType', 'fuelType', 'gearbox', 'v_0', 'v_8', 'v_12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data1 = Train_data.dropna(axis=0, how='any', inplace=False)\n",
    "Y_train = Train_data1['price']\n",
    "X_train = Train_data1[[ 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'bodyType', 'fuelType', 'gearbox',\n",
    "                       'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13','v_14']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑pca降维\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_mat = pca.fit_transform(X_train)\n",
    "X_ones = np.mat(np.ones(X_train_mat.shape[0])).T\n",
    "X_train_mat = np.append(X_ones, X_train_mat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换y\n",
    "Y_train_mat = np.mat(Y_train).T\n",
    "\n",
    "train_Y_ln = np.log(Y_train_mat + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_ln.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7820d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TheResultsShow(X_train_mat, train_Y_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ec5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换成矩阵形式，并生成增广矩阵\n",
    "X_test1_mat = np.mat(X_test)\n",
    "X_ones = np.mat(np.ones(X_test1_mat.shape[0])).T\n",
    "X_test1_mat = np.append(X_ones, X_test1_mat, axis=1)\n",
    "\n",
    "X_train1_mat = np.mat(X_train)\n",
    "X_ones = np.mat(np.ones(X_train1_mat.shape[0])).T\n",
    "X_train1_mat = np.append(X_ones, X_train1_mat, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cf73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TheResultsShow(X_train_09, train_y_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta_hat, y_hat, error_hat = LeastSquareMethod(X_train1_mat, train_y_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_ln = X_test1_mat * Beta_hat\n",
    "y_pre_ln\n",
    "\n",
    "y_pre = np.exp(y_pre_ln)-1\n",
    "y_pre\n",
    "error_hat = y_test_mat - y_pre\n",
    "\n",
    "RegressionDiagnosis(X_test1_mat, y_pre, error_hat)\n",
    "\n",
    "er = ErrorRatio(y_test_mat, y_pre)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑数据划分\n",
    "# 取四分位数删除异常数据\n",
    "#设定法则的左右边界\n",
    "median=y_train.quantile(0.93)\n",
    "\n",
    "#获取在范围内的数据\n",
    "new_num_y=y_train[(median>y_train)]\n",
    "new_num_y\n",
    "\n",
    "y_new = y_train.drop(new_num_y.index[:])\n",
    "y_new = np.mat(y_new)\n",
    "y_new_ln = np.log(y_new+1).T\n",
    "y_new_ln\n",
    "\n",
    "sns.boxplot(y_new_ln,orient=\"v\")\n",
    "\n",
    "X_train_new = X_train.drop(new_num_y.index[:])\n",
    "# 考虑pca降维\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_new_09 = pca.fit_transform(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1fe974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ones = np.mat(np.ones(X_train_new_09.shape[0])).T\n",
    "X_train_new_09 = np.append(X_ones, X_train_new_09, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d789098",
   "metadata": {},
   "outputs": [],
   "source": [
    "TheResultsShow(X_train_new_09, y_new_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58467f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取在范围内的训练数据\n",
    "new_num_y_test=y_test[(median>y_test)]\n",
    "new_num_y_test\n",
    "\n",
    "y_new_test = y_test.drop(new_num_y_test.index[:])\n",
    "y_new_test = np.mat(y_new_test)\n",
    "\n",
    "\n",
    "X_test_new = X_test.drop(new_num_y_test.index[:])\n",
    "\n",
    "X_test_new_09 = pca.transform(X_test_new)\n",
    "X_ones = np.mat(np.ones(X_test_new_09.shape[0])).T\n",
    "X_test_new_09 = np.append(X_ones, X_test_new_09, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta_hat, y_hat, error_hat = LeastSquareMethod(X_train_new_09, y_new_ln)\n",
    "\n",
    "y_pre_ln = X_test_new_09 * Beta_hat\n",
    "y_pre_ln\n",
    "\n",
    "y_pre = np.exp(y_pre_ln)-1\n",
    "y_pre\n",
    "\n",
    "y_test_mat = np.mat(y_test).T\n",
    "\n",
    "error_hat = y_new_test.T - y_pre\n",
    "\n",
    "RegressionDiagnosis(X_test_new_09, y_pre, error_hat)\n",
    "\n",
    "er = ErrorRatio(y_new_test.T, y_pre)\n",
    "er"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
